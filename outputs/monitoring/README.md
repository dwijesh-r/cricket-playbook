# Monitoring Outputs

**Owner:** Jose Mourinho (System Audits) / Ime Udoka (MLOps)
**Generated by:** `scripts/ml_ops/model_monitoring.py`, `scripts/ml_ops/system_health_score.py`

## Directory Structure

```
outputs/monitoring/
├── alerts.json                    # Active alert status (drift, health)
├── README.md                      # This file
└── health_reports/
    └── health_report_YYYYMMDD_HHMMSS.json  # Timestamped health snapshots
```

## Files

### `alerts.json`
Current alert state for model drift detection and system health. Updated on each monitoring run.

### `health_reports/health_report_*.json`
Point-in-time health snapshots generated by `system_health_score.py`. Each report includes:
- **Overall score** (0-100) with status classification
- **Category breakdown** across 6 weighted dimensions (governance, code quality, data robustness, ML rigor, testing, documentation)
- **Benchmark comparisons** against Anthropic AI Safety, Microsoft Responsible AI, Google ML Practices
- **Automation scores** for CI/CD, pipeline, and deployment workflows

## Generation Schedule

| Trigger | Frequency | Workflow |
|---------|-----------|----------|
| ML Health Check | Weekly (Mon 9AM UTC) | `.github/workflows/ml-health-check.yml` |
| Manual dispatch | On demand | `python -m scripts.ml_ops.system_health_score` |

## Interpreting Health Scores

| Score Range | Status | Action |
|-------------|--------|--------|
| 90-100 | EXCELLENT | Maintain current practices |
| 85-89 | GOOD | Minor improvements needed |
| 70-84 | NEEDS WORK | Targeted remediation required |
| <70 | CRITICAL | Immediate attention needed |

## Related Documentation
- System Health Scoring: `scripts/ml_ops/system_health_score.py`
- Model Monitoring: `docs/ml/MONITORING.md`
- Dashboard view: Tech Health tab in Mission Control
